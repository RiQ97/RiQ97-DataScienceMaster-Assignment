{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is the Filter method in feature selection, and how does it work?\n",
    "\n",
    "A1. The Filter method in feature selection evaluates the relevance of each feature individually using statistical techniques, without involving any learning algorithm. It ranks features based on statistical scores and selects the top features that meet a certain criterion.\n",
    "\n",
    "1. **Compute Statistical Scores:** Calculate statistical measures (e.g., correlation, chi-square, mutual information) for each feature concerning the target variable.\n",
    "2. **Rank Features:** Rank the features based on the computed scores.\n",
    "3. **Select Top Features:** Select the top-ranked features based on a predefined threshold or a fixed number of top features.\n",
    "\n",
    "### Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "\n",
    "A2. The Wrapper method evaluates feature subsets by training and testing a specific learning algorithm. It searches for the best subset by iteratively adding or removing features and evaluating model performance.\n",
    "\n",
    "- **Dependency on Learning Algorithm:** Wrapper methods are model-specific and consider feature interactions, while Filter methods are model-agnostic.\n",
    "- **Search Strategy:** Wrapper methods use search strategies (e.g., forward selection, backward elimination) to explore feature subsets, while Filter methods evaluate features individually.\n",
    "- **Evaluation:** Wrapper methods use cross-validation or separate validation sets for evaluation, making them more computationally intensive compared to Filter methods.\n",
    "\n",
    "### Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "\n",
    "A3. Embedded methods perform feature selection as part of the model training process. The model itself identifies the most relevant features during training.\n",
    "\n",
    "Common Techniques used are:\n",
    "- **L1 Regularization (Lasso):** Adds a penalty to the model based on the sum of the absolute values of the coefficients, encouraging sparsity.\n",
    "- **Decision Trees and Tree-Based Methods:** Algorithms like Random Forest and Gradient Boosting inherently perform feature selection based on feature importance scores.\n",
    "- **Elastic Net:** Combines L1 and L2 regularization to balance between feature selection and coefficient shrinkage.\n",
    "\n",
    "### Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "\n",
    "A4. Drawbacks of the filter methods for feature selection\n",
    "- **Ignoring Feature Interactions:** Evaluates each feature independently, ignoring potential interactions between features.\n",
    "- **Model-Agnostic:** May not select features that lead to the best performance for a specific learning algorithm.\n",
    "- **Risk of Irrelevant Features:** Features that appear important statistically may not contribute significantly to the model's predictive power.\n",
    "- **Simplicity:** Simplicity can lead to suboptimal feature subsets compared to more sophisticated methods like Wrapper or Embedded methods.\n",
    "\n",
    "### Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "\n",
    "A5. In this situation I will use the filter methods over the wrapper method:\n",
    "- **High Dimensional Data:** Efficient for datasets with a very large number of features.\n",
    "- **Preprocessing Step:** Quick preprocessing to reduce dimensionality before applying more computationally intensive methods.\n",
    "- **Scalability:** Suitable when processing data at scale with limited computational resources.\n",
    "- **General Feature Selection:** When a general feature selection process is needed for multiple models.\n",
    "\n",
    "### Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "\n",
    "A6. I will do the following steps:\n",
    "\n",
    "1. **Preprocess Data:** Clean and preprocess the dataset, handling missing values and encoding categorical variables.\n",
    "\n",
    "2. **Compute Statistical Measures:** Calculate correlation coefficients for numerical features with the target variable (churn).\n",
    " Use chi-square tests for categorical features with the target variable.\n",
    "\n",
    "3. **Rank Features:** Rank the features based on their correlation coefficients, chi-square scores, or other relevant statistical measures.\n",
    "\n",
    "4. **Select Top Features:** Select the top-ranked features based on a predefined threshold or by choosing a fixed number of top features.\n",
    "\n",
    "5. **Evaluate Selected Features:** Optionally, evaluate the performance of the selected features using a simple model to ensure they contribute to predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('customer_churn.csv')\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Category'] = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=10)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)\n",
    "selected_features = X.columns[chi2_selector.get_support()]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n",
    "\n",
    "A7. I will follow the following steps:\n",
    "\n",
    "1. **Preprocess Data:** Clean and preprocess the dataset, handling missing values and encoding categorical variables.\n",
    "\n",
    "2. **Choose an Appropriate Model:** Select a model that supports embedded feature selection, such as a tree-based model (e.g., Random Forest, Gradient Boosting) or a regularization technique (e.g., Lasso).\n",
    "\n",
    "3. **Train the Model:** Train the selected model on the dataset, allowing it to learn the importance of each feature.\n",
    "\n",
    "4. **Extract Feature Importance:** Extract the feature importance scores from the trained model.\n",
    "\n",
    "5. **Select Top Features:** Rank the features based on their importance scores and select the top features.\n",
    "\n",
    "6. **Evaluate the Model:** Optionally, retrain the model using the selected features and evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('soccer_match_data.csv')\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "X = df.drop('MatchOutcome', axis=1)\n",
    "y = df['MatchOutcome']\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "important_features = X.columns[feature_importances.argsort()[-10:]]\n",
    "print(\"Selected Features:\", important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor.\n",
    "\n",
    "A8. I will follow the following steps:\n",
    "\n",
    "1. **Preprocess Data:** Clean and preprocess the dataset, handling missing values and encoding categorical variables.\n",
    "\n",
    "2. **Choose a Search Strategy:** Select a search strategy, such as forward selection, backward elimination, or recursive feature elimination (RFE).\n",
    "\n",
    "3. **Train and Evaluate Model:** Train a learning algorithm (e.g., linear regression, decision tree) on different subsets of features and evaluate the model performance using cross-validation or a validation set.\n",
    "\n",
    "4. **Iterate Through Feature Subsets:** Iteratively add or remove features based on the chosen search strategy and evaluate their impact on model performance.\n",
    "\n",
    "5. **Select Best Subset:** Select the subset of features that provides the best performance according to the evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('house_prices.csv')\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "selector = RFE(model, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "selected_features = X.columns[selector.support_]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "model.fit(X_train[selected_features], y_train)\n",
    "score = model.score(X_test[selected_features], y_test)\n",
    "print(\"Model Performance:\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
