{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "A1. **Min-Max Scaling** is a feature scaling technique that transforms the data by scaling each feature to a given range, usually 0 to 1. This is achieved using the following formula:\n",
    "$$\n",
    "[ X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} ]\n",
    "$$\n",
    "Where:\n",
    "- X is the original value.\n",
    "- X_min is the minimum value of the feature.\n",
    "- X_max is the maximum value of the feature.\n",
    "- X' is the scaled value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[ 1]\n",
      " [ 5]\n",
      " [10]\n",
      " [15]\n",
      " [20]]\n",
      "Scaled Data:\n",
      " [[0.        ]\n",
      " [0.21052632]\n",
      " [0.47368421]\n",
      " [0.73684211]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = np.array([[1], [5], [10], [15], [20]])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\\n\", data)\n",
    "print(\"Scaled Data:\\n\", scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q2: What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "\n",
    "A2. **Unit Vector Scaling** (or normalization) scales each feature vector to have a unit norm (e.g., L2 norm). The formula for L2 normalization is:\n",
    "\n",
    "$$ [ X' = \\frac{X}{\\|X\\|_2} ] $$\n",
    "\n",
    "Where:\n",
    "$$ ( \\|X\\|_2 ) $$ \n",
    "is the L2 norm of the vector (X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Normalized Data:\n",
      " [[0.4472136  0.89442719]\n",
      " [0.6        0.8       ]\n",
      " [0.6401844  0.76822128]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "normalizer = Normalizer(norm='l2')\n",
    "normalized_data = normalizer.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\\n\", data)\n",
    "print(\"Normalized Data:\\n\", normalized_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Difference:**\n",
    "- **Min-Max Scaling** scales the data to a fixed range, usually [0, 1].\n",
    "- **Unit Vector Scaling** scales the data to have unit norm, often used for directional data.\n",
    "\n",
    "### Q3: What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
    "\n",
    "A3. **Principal Component Analysis (PCA)** is a technique used to reduce the dimensionality of a dataset while preserving as much variance as possible. PCA transforms the data into a set of linearly uncorrelated components called principal components. The first principal component captures the most variance, the second the second most, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components:\n",
      " [[ 0.82797019]\n",
      " [-1.77758033]\n",
      " [ 0.99219749]\n",
      " [ 0.27421042]\n",
      " [ 1.67580142]\n",
      " [ 0.9129491 ]\n",
      " [-0.09910944]\n",
      " [-1.14457216]\n",
      " [-0.43804614]\n",
      " [-1.22382056]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = np.array([[2.5, 2.4],\n",
    "                 [0.5, 0.7],\n",
    "                 [2.2, 2.9],\n",
    "                 [1.9, 2.2],\n",
    "                 [3.1, 3.0],\n",
    "                 [2.3, 2.7],\n",
    "                 [2, 1.6],\n",
    "                 [1, 1.1],\n",
    "                 [1.5, 1.6],\n",
    "                 [1.1, 0.9]])\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "principal_components = pca.fit_transform(data)\n",
    "\n",
    "print(\"Principal Components:\\n\", principal_components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "A4. PCA is often used for feature extraction because it transforms the original features into a new set of features (principal components) that are uncorrelated and capture the maximum variance in the data. These principal components can be used as new features for a machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components:\n",
      " [[ 0.82797019]\n",
      " [-1.77758033]\n",
      " [ 0.99219749]\n",
      " [ 0.27421042]\n",
      " [ 1.67580142]\n",
      " [ 0.9129491 ]\n",
      " [-0.09910944]\n",
      " [-1.14457216]\n",
      " [-0.43804614]\n",
      " [-1.22382056]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.array([[2.5, 2.4],\n",
    "                 [0.5, 0.7],\n",
    "                 [2.2, 2.9],\n",
    "                 [1.9, 2.2],\n",
    "                 [3.1, 3.0],\n",
    "                 [2.3, 2.7],\n",
    "                 [2, 1.6],\n",
    "                 [1, 1.1],\n",
    "                 [1.5, 1.6],\n",
    "                 [1.1, 0.9]])\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "principal_components = pca.fit_transform(data)\n",
    "\n",
    "print(\"Principal Components:\\n\", principal_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q5: You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
    "\n",
    "A5. To preprocess the data using Min-Max scaling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price  Rating  DeliveryTime\n",
      "0   0.00    0.50      0.333333\n",
      "1   0.25    0.75      0.833333\n",
      "2   0.50    1.00      0.000000\n",
      "3   0.75    0.25      1.000000\n",
      "4   1.00    0.00      0.666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. Import necessary libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#2. Prepare the dataset\n",
    "\n",
    "data = pd.DataFrame({\n",
    "        'Price': [10, 15, 20, 25, 30],\n",
    "        'Rating': [3, 4, 5, 2, 1],\n",
    "        'DeliveryTime': [30, 45, 20, 50, 40]\n",
    "    })\n",
    "\n",
    "\n",
    "#3. Apply Min-Max scaling\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "print(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q6: You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
    "\n",
    "A6. To use PCA for dimensionality reduction in predicting stock prices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2\n",
      "0   0.145171  0.154351\n",
      "1   0.140354  0.473175\n",
      "2   0.327887  0.342398\n",
      "3   0.334707  0.593629\n",
      "4  -0.410961  0.265656\n",
      "..       ...       ...\n",
      "95 -0.326036 -0.650610\n",
      "96 -0.029662  0.458845\n",
      "97 -0.363441 -0.077084\n",
      "98  0.202653  0.308292\n",
      "99  0.282327  0.279806\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#1. Import necessary libraries\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#2. Prepare the dataset\n",
    "\n",
    "data = pd.DataFrame({\n",
    "        'Feature1': np.random.rand(100),\n",
    "        'Feature2': np.random.rand(100),\n",
    "        'Feature3': np.random.rand(100),\n",
    "        'Feature4': np.random.rand(100),\n",
    "        'Feature5': np.random.rand(100)\n",
    "    })\n",
    "\n",
    "\n",
    "#3. Apply PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # Reduce to 2 principal components\n",
    "principal_components = pca.fit_transform(data)\n",
    "pca_df = pd.DataFrame(principal_components, columns=['PC1', 'PC2'])\n",
    "print(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Q7: For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.        ]\n",
      " [-0.57894737]\n",
      " [-0.05263158]\n",
      " [ 0.47368421]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#A7.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = np.array([1, 5, 10, 15, 20]).reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q8: For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "A8. To perform feature extraction using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44637188 0.64108974 0.7663485  0.8877167  1.        ]\n",
      "[[-0.47630511  0.05251609]\n",
      " [ 0.55898603  0.35178451]\n",
      " [ 0.5815246  -0.05431049]\n",
      " [ 0.53586332 -0.11176342]\n",
      " [-0.48307167 -0.00769832]\n",
      " [-0.40071401  0.49961394]\n",
      " [ 0.52552511  0.20260653]\n",
      " [ 0.51901375 -0.29069652]\n",
      " [-0.44914701  0.10796691]\n",
      " [-0.43513098  0.20559456]\n",
      " [ 0.49021828 -0.41375791]\n",
      " [-0.4189681   0.36698166]\n",
      " [ 0.51002035  0.1570661 ]\n",
      " [ 0.48433065 -0.28651128]\n",
      " [ 0.48056675 -0.36764779]\n",
      " [-0.50797246  0.07354827]\n",
      " [ 0.5123688   0.22143492]\n",
      " [-0.4636189  -0.06440498]\n",
      " [ 0.54600764 -0.21587076]\n",
      " [ 0.48885654 -0.31497601]\n",
      " [-0.50023497 -0.55212064]\n",
      " [-0.46928775  0.05182924]\n",
      " [-0.46425341 -0.00667797]\n",
      " [-0.50498423 -0.06111888]\n",
      " [ 0.47482471 -0.62505295]\n",
      " [ 0.52553084  0.17752567]\n",
      " [ 0.5138526  -0.18716527]\n",
      " [ 0.55927582  0.24016118]\n",
      " [-0.49641444 -0.58037852]\n",
      " [ 0.54973331  0.40883433]\n",
      " [-0.46101069  0.12182765]\n",
      " [-0.5142002  -0.4960013 ]\n",
      " [ 0.56308889  0.20530628]\n",
      " [ 0.4621888  -0.96919999]\n",
      " [ 0.55810281  0.22363077]\n",
      " [ 0.57591031  0.43962049]\n",
      " [-0.43753642  0.46150871]\n",
      " [ 0.55006964 -0.28583112]\n",
      " [-0.47599113 -0.23109012]\n",
      " [-0.49274687 -0.42977851]\n",
      " [-0.46074547  0.40008973]\n",
      " [-0.46766696  0.32966191]\n",
      " [-0.42930322  0.42233096]\n",
      " [ 0.57839706  0.13209486]\n",
      " [ 0.5682904   0.20436486]\n",
      " [-0.44233183  0.59613992]\n",
      " [-0.49858854  0.30471262]\n",
      " [ 0.49307007 -0.46366347]\n",
      " [ 0.53688635  0.20274533]\n",
      " [-0.5539939  -0.32765286]\n",
      " [-0.4995444  -0.4128623 ]\n",
      " [ 0.56988793  0.07887224]\n",
      " [-0.46822325 -0.20730661]\n",
      " [ 0.46822532 -0.14325402]\n",
      " [ 0.58171712  0.36056522]\n",
      " [-0.49500625  0.18240441]\n",
      " [-0.51577086 -0.5341876 ]\n",
      " [-0.50843172 -0.15167174]\n",
      " [-0.49474451 -0.17496637]\n",
      " [ 0.49528229 -0.37035919]\n",
      " [-0.51240108 -0.57846909]\n",
      " [-0.47752647 -0.11492497]\n",
      " [ 0.51731665 -0.19393747]\n",
      " [-0.47621884  0.2518341 ]\n",
      " [ 0.57348649  0.47363635]\n",
      " [ 0.49698939 -0.02758457]\n",
      " [ 0.52098189  0.26778068]\n",
      " [-0.46621304  0.15876467]\n",
      " [-0.48865065 -0.36899738]\n",
      " [-0.40929354  0.14936364]\n",
      " [ 0.54388035 -0.15524122]\n",
      " [-0.50494485 -0.2408331 ]\n",
      " [ 0.5649431   0.34985083]\n",
      " [ 0.52250583 -0.17860207]\n",
      " [ 0.50227887 -0.01931787]\n",
      " [ 0.54244502  0.29617816]\n",
      " [-0.46193986  0.10756452]\n",
      " [-0.44493834  0.06640812]\n",
      " [-0.53676356 -0.74747466]\n",
      " [-0.50622925 -0.53569687]\n",
      " [-0.43326422  0.35055164]\n",
      " [-0.4295026   0.68877218]\n",
      " [ 0.49556416 -0.21203613]\n",
      " [-0.4575583  -0.04236267]\n",
      " [ 0.55039015 -0.07278628]\n",
      " [-0.3925606   0.32512279]\n",
      " [ 0.54938398  0.17436781]\n",
      " [ 0.58788787 -0.06566032]\n",
      " [-0.51443283 -0.24066489]\n",
      " [ 0.52011287 -0.20030715]\n",
      " [-0.46117565  0.03470677]\n",
      " [-0.45927616  0.31136537]\n",
      " [ 0.57402496  0.46206753]\n",
      " [ 0.56265079  0.19360686]\n",
      " [ 0.47947624 -0.43344275]\n",
      " [-0.44917702  0.53010568]\n",
      " [-0.43420077  0.10785137]\n",
      " [-0.43221641 -0.02132086]\n",
      " [-0.45827819  0.43077852]\n",
      " [-0.4692332   0.27361979]]\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Height': np.random.rand(100),\n",
    "    'Weight': np.random.rand(100),\n",
    "    'Age': np.random.rand(100),\n",
    "    'Gender': np.random.randint(0, 2, 100),\n",
    "    'BloodPressure': np.random.rand(100)\n",
    "    })\n",
    "# Determine the number of principal components\n",
    "pca = PCA().fit(data)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(explained_variance)\n",
    "\n",
    "# Choose the number of components\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(data)\n",
    "print(principal_components)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
