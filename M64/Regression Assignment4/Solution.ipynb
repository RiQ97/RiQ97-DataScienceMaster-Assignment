{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "A1. **Lasso Regression** (Least Absolute Shrinkage and Selection Operator) is a linear regression technique that includes a penalty term proportional to the sum of the absolute values of the coefficients. This penalty causes some coefficients to shrink to zero, effectively performing feature selection.\n",
    "\n",
    "**Differences from Other Regression Techniques**:\n",
    "- **Ordinary Least Squares (OLS) Regression**: OLS minimizes the sum of squared residuals without any penalty term, so it does not perform feature selection.\n",
    "- **Ridge Regression**: Ridge adds a penalty proportional to the sum of squared coefficients (L2 regularization), shrinking coefficients but not necessarily to zero. Lasso, on the other hand, uses L1 regularization, which can shrink some coefficients to zero.\n",
    "- **Elastic Net**: Combines both L1 (Lasso) and L2 (Ridge) penalties, balancing feature selection (Lasso) and coefficient shrinkage (Ridge).\n",
    "\n",
    "### Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "A2. The main advantage of Lasso Regression in feature selection is its ability to shrink some coefficients to exactly zero, effectively excluding less important features from the model. This makes Lasso particularly useful when you want to reduce the complexity of the model by automatically selecting a subset of the most relevant features.\n",
    "\n",
    "### Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "A3. In Lasso Regression, the magnitude of the coefficients indicates the strength of the relationship between each independent variable and the dependent variable, similar to other regression models. However:\n",
    "- **Zero Coefficients**: Variables with coefficients shrunk to zero are considered irrelevant and excluded from the model.\n",
    "- **Non-Zero Coefficients**: The non-zero coefficients are the features that the model has identified as important predictors of the dependent variable.\n",
    "\n",
    "### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "A4. The main tuning parameter in Lasso Regression is the regularization parameter λ (often denoted as alpha):\n",
    "- **Regularization Parameter λ**: Controls the strength of the L1 penalty. A larger λ increases the penalty, leading to more coefficients being shrunk to zero (greater feature selection). A smaller λ reduces the penalty, allowing more features to be retained in the model.\n",
    "- **Effects on Performance**: A well-chosen λ balances bias and variance, improving the model's generalization. Too large λ may lead to underfitting, while too small λ might result in overfitting.\n",
    "\n",
    "### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "A5. Yes, Lasso Regression can be adapted for non-linear regression problems by transforming the input features. This can be done through:\n",
    "- **Polynomial Features**: Creating polynomial combinations of the original features to capture non-linear relationships.\n",
    "- **Interaction Terms**: Including interaction terms between features.\n",
    "- **Kernel Methods**: Applying kernel tricks to map the input space into a higher-dimensional space where linear relationships can capture the original non-linear structure.\n",
    "\n",
    "After transforming the features, Lasso Regression can be applied as usual, with the L1 penalty helping in feature selection even among these derived features.\n",
    "\n",
    "### Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "A6. The key differences between Ridge Regression and Lasso Regression are:\n",
    "- **Penalty Type**: Ridge uses an L2 penalty (sum of squared coefficients), while Lasso uses an L1 penalty (sum of absolute values of coefficients).\n",
    "- **Coefficient Shrinkage**: Ridge shrinks all coefficients but does not set any to zero, whereas Lasso can shrink some coefficients exactly to zero, effectively selecting a subset of features.\n",
    "- **Feature Selection**: Lasso can be used for feature selection, whereas Ridge is better for handling multicollinearity without necessarily reducing the number of features.\n",
    "\n",
    "### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "A7. Yes, Lasso Regression can handle multicollinearity, but it does so differently than Ridge Regression. In the presence of highly correlated features, Lasso tends to select one of them and shrink the coefficients of the others to zero, effectively excluding them from the model. This is because the L1 penalty encourages sparsity, leading to feature selection.\n",
    "\n",
    "### Q8. How do you choose the optimal value of the regularization parameter (λ) in Lasso Regression?\n",
    "\n",
    "A8. The optimal value of the regularization parameter λ in Lasso Regression can be chosen using:\n",
    "- **Cross-Validation**: The most common method is k-fold cross-validation, where the dataset is split into k subsets, and the model is trained on k-1 subsets while validated on the remaining one. This process is repeated for different values of λ, and the one that minimizes the validation error is chosen.\n",
    "- **Grid Search**: A grid of λ values is defined, and the best λ is selected based on model performance metrics like mean squared error (MSE).\n",
    "- **Regularization Path**: Algorithms like LARS (Least Angle Regression) compute the full path of solutions as λ varies, and the optimal λ can be selected based on cross-validation or other criteria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
