{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "\n",
    "A1. **Missing Values:** occur when no data is available for a particular attribute or observation in a dataset. They can result from various reasons, such as errors in data collection, incomplete responses, or data corruption.\n",
    "\n",
    "It is essential to handle because of the following reasons : \n",
    "- **Accuracy:** Missing values can lead to inaccurate analysis and skewed results.\n",
    "- **Model Performance:** Many algorithms require complete data and may fail or perform poorly with missing values.\n",
    "- **Bias:** Ignoring missing values can introduce bias, affecting the validity of the analysis.\n",
    "\n",
    "**Algorithms Not Affected by Missing Values:**\n",
    "- **Decision Trees** (e.g., CART, Random Forests)\n",
    "- **k-Nearest Neighbors (k-NN)**\n",
    "- **Naive Bayes**\n",
    "\n",
    "These algorithms can handle missing values internally by using surrogate splits (in the case of decision trees) or ignoring missing values during calculations (in k-NN and Naive Bayes).\n",
    "\n",
    "### Q2: List down techniques used to handle missing data. Give an example of each with Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "**1. Imputation (Mean/Median/Mode):**\n",
      "*************************************\n",
      "mean    Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "median    Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "mode    Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "************************************\n",
      "**2. Forward Fill / Backward Fill:**\n",
      "************************************\n",
      "   Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "   Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "*********************\n",
      "**3. Interpolation:**\n",
      "*********************\n",
      "   Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "*******************************\n",
      "**4. Dropping Missing Values:**\n",
      "*******************************\n",
      "   Feature1\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       4.0\n",
      "4       5.0\n",
      "*******************************************************************\n",
      "**5. Using a Machine Learning Model for Imputation (KNN Imputer):**\n",
      "*******************************************************************\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RiQ\\AppData\\Local\\Temp\\ipykernel_14204\\489657238.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Feature1'].fillna(mean_value, inplace=True)\n",
      "C:\\Users\\RiQ\\AppData\\Local\\Temp\\ipykernel_14204\\489657238.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Feature1'].fillna(median_value, inplace=True)\n",
      "C:\\Users\\RiQ\\AppData\\Local\\Temp\\ipykernel_14204\\489657238.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Feature1'].fillna(mode_value, inplace=True)\n",
      "C:\\Users\\RiQ\\AppData\\Local\\Temp\\ipykernel_14204\\489657238.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\RiQ\\AppData\\Local\\Temp\\ipykernel_14204\\489657238.py:35: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#A2.\n",
    "print('*************************************')\n",
    "print('**1. Imputation (Mean/Median/Mode):**')\n",
    "print('*************************************')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'Feature1': [1, 2, np.nan, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mean imputation\n",
    "mean_value = df['Feature1'].mean()\n",
    "df['Feature1'].fillna(mean_value, inplace=True)\n",
    "print('mean',df)\n",
    "\n",
    "# Median imputation\n",
    "median_value = df['Feature1'].median()\n",
    "df['Feature1'].fillna(median_value, inplace=True)\n",
    "print('median',df)\n",
    "\n",
    "# Mode imputation\n",
    "mode_value = df['Feature1'].mode()[0]\n",
    "df['Feature1'].fillna(mode_value, inplace=True)\n",
    "print('mode',df)\n",
    "\n",
    "print('************************************')\n",
    "print('**2. Forward Fill / Backward Fill:**')\n",
    "print('************************************')\n",
    "\n",
    "# Forward fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "print(df)\n",
    "# Backward fill\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "print(df)\n",
    "\n",
    "print('*********************')\n",
    "print('**3. Interpolation:**')\n",
    "print('*********************')\n",
    "\n",
    "# Interpolation\n",
    "df['Feature1'] = df['Feature1'].interpolate()\n",
    "print(df)\n",
    "\n",
    "print('*******************************')\n",
    "print('**4. Dropping Missing Values:**')\n",
    "print('*******************************')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "print(df)\n",
    "\n",
    "print('*******************************************************************')\n",
    "print('**5. Using a Machine Learning Model for Imputation (KNN Imputer):**')\n",
    "print('*******************************************************************')\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Sample data\n",
    "data = {'Feature1': [1, 2, np.nan, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Explain imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "A3. **Imbalanced Data:**  \n",
    "Imbalanced data occurs when the classes in the dataset are not represented equally. For example, in a binary classification problem, one class may have significantly more examples than the other.\n",
    "\n",
    "**Consequences of Not Handling Imbalanced Data:**\n",
    "- **Model Bias:** The model may be biased toward the majority class, leading to poor performance on the minority class.\n",
    "- **Poor Generalization:** The model might not generalize well to new data, especially for the minority class.\n",
    "- **Misleading Metrics:** Performance metrics such as accuracy may be misleading if the majority class dominates the dataset.\n",
    "\n",
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
    "\n",
    "A4. **Up-sampling:** involves increasing the number of instances in the minority class by duplicating existing samples or generating new samples.\n",
    "**Down-sampling:** involves reducing the number of instances in the majority class to match the number of instances in the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1 Class\n",
      "2         3     B\n",
      "3         4     B\n",
      "4         5     B\n",
      "0         1     A\n",
      "1         2     A\n",
      "1         2     A\n",
      "   Feature1 Class\n",
      "4         5     B\n",
      "3         4     B\n",
      "0         1     A\n",
      "1         2     A\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Sample data\n",
    "data = {'Feature1': [1, 2, 3, 4, 5],\n",
    "        'Class': ['A', 'A', 'B', 'B', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['Class'] == 'B']\n",
    "df_minority = df[df['Class'] == 'A']\n",
    "\n",
    "# Up-sample minority class\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=0)\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "print(df_balanced)\n",
    "\n",
    "# Down-sample majority class\n",
    "df_majority_downsampled = resample(df_majority, replace=False,  n_samples=len(df_minority), random_state=0)\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "print(df_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "A5. **Data Augmentation:** is a technique used to artificially increase the size of a dataset by creating modified versions of existing data. This is commonly used in image data to create variations (e.g., rotations, translations) and enhance model performance.\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique):**  \n",
    "SMOTE is a technique used to generate synthetic examples in the feature space for the minority class by interpolating between existing minority class samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [2, 3], [3, 4], [4, 5]] [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Sample data\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 5]]  # Feature matrix\n",
    "y = [0, 0, 1, 1]  # Target variable (imputed labels for the minority class)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "print(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "A6. **Outliers:** are data points that differ significantly from the majority of the data. They are extreme values that lie outside the range of normal data.\n",
    "\n",
    "**Importance of Handling Outliers:**\n",
    "- **Model Accuracy:** Outliers can skew statistical measures and affect model accuracy.\n",
    "- **Data Distribution:** They can distort the distribution of the data, affecting assumptions made by some algorithms.\n",
    "- **Interpretability:** Outliers may affect the interpretability of the model's results.\n",
    "\n",
    "**Handling Outliers:**\n",
    "- **Remove:** Exclude outliers if they are errors or not representative.\n",
    "- **Transform:** Apply transformations like log or square root to reduce the impact of outliers.\n",
    "- **Impute:** Replace outliers with more central values or median values.\n",
    "\n",
    "### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "A7. **Techniques for Handling Missing Data:**\n",
    "- **Imputation:** Fill missing values with mean, median, mode, or use advanced methods like KNN or regression imputation.\n",
    "- **Removal:** Drop rows or columns with missing values if the percentage of missing data is small.\n",
    "- **Prediction:** Use machine learning models to predict and fill in missing values based on other data.\n",
    "- **Flag and Fill:** Create a new binary feature to indicate missingness and then impute the values.\n",
    "\n",
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "\n",
    "A8. **Strategies to Determine Missing Data Patterns:**\n",
    "- **Visual Inspection:** Use visualizations like heatmaps to check patterns of missing data.\n",
    "- **Statistical Tests:** Conduct tests to determine if missing data is related to other variables (e.g., Little's MCAR test).\n",
    "- **Correlation Analysis:** Analyze correlations between missingness and other features to detect patterns.\n",
    "- **Missing Data Mechanism:** Assess if data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\n",
    "\n",
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "A9. **Strategies for Evaluating Imbalanced Datasets:**\n",
    "- **Use Metrics Suitable for Imbalance:** Utilize metrics such as precision, recall, F1-score, and ROC-AUC instead of accuracy.\n",
    "- **Cross-Validation:** Use stratified k-fold cross-validation to ensure each fold has a representative proportion of classes.\n",
    "- **Resampling Techniques:** Apply up-sampling or down-sampling to balance the classes in training data.\n",
    "- **Adjust Class Weights:** Use algorithms that allow setting class weights to handle imbalance (e.g., class_weight parameter in scikit-learn).\n",
    "\n",
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "\n",
    "A10. **Balancing Dataset by Down-Sampling:**\n",
    "- **Random Down-Sampling:** Randomly reduce the number of samples in the majority class to match the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1   Satisfaction\n",
      "0         1      Satisfied\n",
      "1         2      Satisfied\n",
      "0         1      Satisfied\n",
      "1         2      Satisfied\n",
      "1         2      Satisfied\n",
      "2         3      Satisfied\n",
      "0         1      Satisfied\n",
      "3         4  Not Satisfied\n",
      "4         5  Not Satisfied\n",
      "5         6  Not Satisfied\n",
      "6         7  Not Satisfied\n",
      "7         8  Not Satisfied\n",
      "8         9  Not Satisfied\n",
      "9        10  Not Satisfied\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "data = {'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'Satisfaction': ['Satisfied', 'Satisfied', 'Satisfied', 'Not Satisfied', 'Not Satisfied', 'Not Satisfied', 'Not Satisfied', 'Not Satisfied', 'Not Satisfied', 'Not Satisfied']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_majority = df[df['Satisfaction'] == 'Satisfied']\n",
    "df_minority = df[df['Satisfaction'] == 'Not Satisfied']\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, n_samples=len(df_minority), random_state=0)\n",
    "\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "print(df_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "\n",
    "A11. **Balancing Dataset by Up-Sampling:**\n",
    "- **Random Up-Sampling:** Increase the number of samples in the minority class by duplicating existing samples.\n",
    "\n",
    "- **SMOTE:** Generate synthetic samples for the minority class to increase its representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]] [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Sample data\n",
    "X = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]  # Features\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # Target (Imbalanced dataset)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "print(X_res, y_res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
